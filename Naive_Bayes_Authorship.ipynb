{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes Authorship.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Y82OH4fyex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fileinput\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQWA-qcgKAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "77117f7c-e514-4dc1-ce8f-fe0b1ceaef60"
      },
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSUxTwZ0gL8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('matthew.txt')\n",
        "JohnText = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4HIKdZtgTdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('john.txt')\n",
        "MatthewText = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P58qI_MgVdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25c668d4-b867-480e-86aa-7d65e1604c09"
      },
      "source": [
        "print(MatthewText[:20])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:1 In the beginning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs2T1U8_gXSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chunk the text\n",
        "def Chunkr(text, size):\n",
        "  chunkt = []\n",
        "  tokentext = nltk.sent_tokenize(text)\n",
        "  j=0\n",
        "  for i in range(0, len(tokentext), size):\n",
        "    chunkt.append(\" \".join(tokentext[i:i+size]))\n",
        "    j+=1\n",
        "  return chunkt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEWIox99gZQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gets rid of all of references and newlines\n",
        "def KeepAlpha(text):\n",
        "  words = word_tokenize(text)\n",
        "  for word in words:\n",
        "    if any(c.isdigit() or c == '\\n' for c in word):\n",
        "      words.remove(word)\n",
        "    i=0\n",
        "  stringtext = \" \".join(str(e) for e in words)\n",
        "  return stringtext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1s26Cx7gbRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average Sentence Length (In a standardized rating system)\n",
        "def AvgSentLength(text):\n",
        "  words = word_tokenize(text)\n",
        "  sentences = sent_tokenize(text)\n",
        "  wordcount = len(words)\n",
        "  sentcount = len(sentences)\n",
        "  avglength = (wordcount/sentcount)\n",
        "  if avglength < 5:\n",
        "    stdlength = 'small'\n",
        "  elif avglength >= 5 and avglength < 8:\n",
        "    stdlength = 'medium'\n",
        "  else:\n",
        "    stdlength = 'long'\n",
        "  return stdlength"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm3b-mdbgdX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the average length of words used\n",
        "def AvgWordLength(text):\n",
        "  words = word_tokenize(text)\n",
        "  wordlength = sum(len(word) for word in words)/len(text.split(\" \"))\n",
        "\n",
        "  if wordlength < 4:\n",
        "    stdlength = 'small'\n",
        "  elif wordlength >=4 and wordlength < 6:\n",
        "    stdlength = 'medium'\n",
        "  else:\n",
        "    stdlength = 'long'\n",
        "  return stdlength"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7alzi5Ogf79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No. of Syllables per word\n",
        "def SylCount(word):\n",
        "  word.lower()\n",
        "  count = 0\n",
        "  vowels = 'aeiouy'\n",
        "  if word[0] in vowels:\n",
        "    count += 1\n",
        "\n",
        "  for index in range(1, len(word)):\n",
        "    if word[index] in vowels and word[index-1] not in vowels:\n",
        "      count+=1\n",
        "      if word.endswith('e'):\n",
        "       count -= 1\n",
        "  if count == 0:\n",
        "    count += 1\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuOIxRIKgigo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average Syllable Count\n",
        "def AvgSylCount(text):\n",
        "  words = (word_tokenize(text))\n",
        "  wordcount = len(words)\n",
        "  sylcount = 0\n",
        "  for i in range(wordcount):\n",
        "    if words[i] != \" \":\n",
        "      sylcount += SylCount(words[i])\n",
        "  avg = sylcount/wordcount\n",
        "\n",
        "  if avg > 1.7:\n",
        "    avg_std = 'high'\n",
        "  elif avg <= 1.7 and avg > 1.2:\n",
        "    avg_std = 'medium'\n",
        "  else:\n",
        "    avg_std = 'low'\n",
        "  return avg_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf82oYe5glWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average Punctuation Count\n",
        "def PunctFreq(text):\n",
        "  textlength = len(text)\n",
        "  punct = {'.','\\,',':','\\;''-','?'}\n",
        "  pcount = 0\n",
        "  for i in range(textlength):\n",
        "    if text[i] in punct:\n",
        "      pcount +=1\n",
        "  freq = pcount/textlength\n",
        "\n",
        "  if freq < .006:\n",
        "    freq_std = 'low'\n",
        "  elif freq >= .006 and freq < .0095:\n",
        "    freq_std = 'medium'\n",
        "  else:\n",
        "    freq_std = 'high'\n",
        "\n",
        "  return freq_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvsF8506gn95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def POSTag(text):\n",
        "  text = text.lower()\n",
        "  words = nltk.word_tokenize(text)\n",
        "  taggedWords = nltk.pos_tag(words)\n",
        "  fd = nltk.FreqDist(tag for (word, tag) in taggedWords)\n",
        "  sentCount = len(nltk.sent_tokenize(text))\n",
        "  posrate = len(fd)/sentCount\n",
        "\n",
        "  if posrate < 3.45:\n",
        "    posrate_std = 'low'\n",
        "  elif posrate >= 3.45 and posrate < 3.65:\n",
        "    posrate_std = 'medium'\n",
        "  else:\n",
        "    posrate_std = 'high'\n",
        "\n",
        "  return posrate_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znsT4aXXgp-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gunning-Fog Index\n",
        "def GFIndex(text):\n",
        "  compwords = 0\n",
        "  words = word_tokenize(text)\n",
        "  totalwords = len(words)\n",
        "  totalsentences = len(sent_tokenize(text))\n",
        "  \n",
        "  for i in range(totalwords):\n",
        "    if len(words[i]) > 6 and SylCount(words[i]) > 3:\n",
        "      compwords+=1\n",
        "\n",
        "  gf = 0.4*((totalwords/totalsentences)+100*(compwords/totalwords))\n",
        "\n",
        "  if gf > 12:\n",
        "    gf_index = 'college'\n",
        "  elif gf <= 12 and gf >8:\n",
        "    gf_index = 'hs'\n",
        "  else:\n",
        "    gf_index = 'elementary'\n",
        "  \n",
        "  return gf_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cifFKLLZgs1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SMOG Readability Formula\n",
        "def SMOGIndex(text):\n",
        "  count = 0\n",
        "  words = word_tokenize(text)\n",
        "  for word in words:\n",
        "    if SylCount(word) > 1:\n",
        "      count += 1\n",
        "  totalsentences = len(sent_tokenize(text))\n",
        "  gl = 1.0430*np.sqrt(count*(30/totalsentences))+3.1291\n",
        "\n",
        "  if gl > 90:\n",
        "    gl_index = 'college'\n",
        "  elif gl <= 90 and gl > 30:\n",
        "    gl_index = 'hs'\n",
        "  else:\n",
        "    gl_index = 'elem'\n",
        "\n",
        "  return gl_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAc_LcrjgvHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function Word Frequency\n",
        "def FunctionFreq(text):\n",
        "  functionwords = [\n",
        "    \"of\", \"at\", \"the\", \"there\", \"do\",\"be\",\"have\",\n",
        "    \"and\",\"but\",\"or\",\"nor\",\"yet\",\"for\",\"so\",\"has\",\n",
        "    \"will\",\"is\",\"been\",\"a\",\"an\",\"since\",\"as\",\"we\",\n",
        "    \"thee\",\"thine\",\"ye\",\"his\",\"you\",\"thou\",\"me\",\"i\",\n",
        "    \"your\",\"yours\",\"she\",\"he\",\"her\",\"hers\",\"his\",\n",
        "    \"anybody\",\"that\",\"when\",\"while\",\"although\",\"whereas\",\n",
        "    \"therfore\",\"then\",\"am\",\"my\",\"much\",\"more\",\"either\",\n",
        "    \"neither\",\"thus\",\"no\",\"not\",\"it\",\"got\",\"are\",\n",
        "    \"almost\",\"always\",\"never\",\"another\",\"however\",\"both\",\n",
        "    \"between\",\"by\",\"cannot\",\"can\",\"does\",\"down\",\"during\",\n",
        "    \"which\",\"hereby\",\"herein\",\"how\",\"if\",\"in\",\"out\",\n",
        "    \"indeed\",\"its\",\"might\",\"lot\",\"most\",\"mostly\",\n",
        "    \"meanwhile\",\"meantime\",\"need\",\"near\",\"far\",\"nothing\",\n",
        "    \"often\",\"off\",\"once\",\"only\",\"onto\",\"other\",\"others\",\n",
        "    \"ought\",\"shall\",\"rather\",\"perhaps\",\"should\",\"some\",\n",
        "    \"such\",\"thence\",\"hence\",\"these\",\"too\",\"also\",\"toward\",\n",
        "    \"until\",\"us\",\"what\",\"when\",\"whence\",\"where\",\"who\",\"how\",\n",
        "    \"whoever\",\"whomever\"\n",
        "    ]\n",
        "  text.lower()\n",
        "  words = word_tokenize(text)\n",
        "  count = 0\n",
        "  for word in words:\n",
        "    if word in functionwords:\n",
        "      count += 1\n",
        "  funcfreq = count/len(words)\n",
        "\n",
        "  if funcfreq > .33:\n",
        "    ff_std = 'high'\n",
        "  elif funcfreq <= .33 and funcfreq > .25:\n",
        "    ff_std = 'medium'\n",
        "  else:\n",
        "    ff_std = 'low'\n",
        "  \n",
        "  return ff_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05d_PcLpgx1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pronoun Frequency\n",
        "def PronounFreq(text):\n",
        "  pronouns = [\n",
        "    \"thy\", \"thou\", \"thee\", \"thine\", \n",
        "    \"ye\", \"you\", \"he\", \"she\", \"her\",\n",
        "    \"hers\",\"his\", \"my\",\"me\", \"i\",\n",
        "    \"your\", \"yours\", \"we\",\"anybody\",\"it\"\n",
        "    \"who\",\"whom\",\"others\",\"these\", \"this\", \n",
        "    \"that\"]\n",
        "  text.lower()\n",
        "  words = word_tokenize(text)\n",
        "  count = 0\n",
        "  for word in words:\n",
        "    if word in pronouns:\n",
        "      count += 1\n",
        "  pronounfreq = count/len(words)\n",
        "\n",
        "  if pronounfreq > .07:\n",
        "    pf_std = 'high'\n",
        "  elif pronounfreq <= .07 and pronounfreq >.05:\n",
        "    pf_std = 'medium'\n",
        "  else:\n",
        "    pf_std = 'low'\n",
        "\n",
        "  return pf_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6stDTs7wg1Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Frequency of negation words\n",
        "def NegationFreq(text):\n",
        "  negations = [\n",
        "    \"no\",\"not\",\"nor\",\"neither\",\"nobody\",\n",
        "    \"none\",\"nothing\",\"nowhere\",\"cannot\"]\n",
        "  text.lower()\n",
        "  words = word_tokenize(text)\n",
        "  count = 0\n",
        "  for word in words:\n",
        "    if word in negations:\n",
        "      count += 1\n",
        "  negationfreq = count/len(words)\n",
        "\n",
        "  if negationfreq > .03:\n",
        "    nf_std = 'high'\n",
        "  elif negationfreq <= .03 and negationfreq > .01:\n",
        "    nf_std = 'medium'\n",
        "  else:\n",
        "    nf_std = 'low'\n",
        "  \n",
        "  return nf_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyH0pu-4g4aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freq. of Words with more than 6 letters\n",
        "def LargeWordFreq(text):\n",
        "  words = word_tokenize(text)\n",
        "  count = 0\n",
        "  for word in words:\n",
        "    if len(word)>6:\n",
        "      count +=1\n",
        "  largefreq = count/len(words)\n",
        "\n",
        "  if largefreq > 7:\n",
        "    lf_std = 'high'\n",
        "  elif largefreq <= 7 and largefreq > 4:\n",
        "    lf_std = 'medium'\n",
        "  else:\n",
        "    lf_std = 'low'\n",
        "  \n",
        "  return lf_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89ouK_slhGW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freq. of Words with less than 4 letters\n",
        "def SmallWordFreq(text):\n",
        "  words = word_tokenize(text)\n",
        "  count = 0\n",
        "  for word in words:\n",
        "    if len(word)<4:\n",
        "      count =+ 1\n",
        "  smallfreq = count/len(words)\n",
        "\n",
        "  if smallfreq > 7:\n",
        "    sf_std = 'high'\n",
        "  elif smallfreq <= 7 and smallfreq > 4:\n",
        "    sf_std = 'medium'\n",
        "  else:\n",
        "    sf_std = 'low'\n",
        "  \n",
        "  return sf_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU4BcfEphIeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the total amount of different words used\n",
        "def DiffWordCount(text):\n",
        "    punct = [',','.','/',';',':','?','!','-','(',')']\n",
        "    text = text.lower()\n",
        "    for x in text: \n",
        "            if x in punct: \n",
        "                text = text.replace(x, \"\")\n",
        "    words = nltk.word_tokenize(text)\n",
        "    fd = nltk.FreqDist(words)\n",
        "    diffwords = len(fd)\n",
        "\n",
        "    if diffwords < 90:\n",
        "      dw_std = 'low'\n",
        "    elif diffwords >=90 and diffwords < 130:\n",
        "      dw_std = 'medium'\n",
        "    else:\n",
        "      dw_std = 'high'\n",
        "\n",
        "    return dw_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkOMWylPhKTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha_text = {}\n",
        "chunk_text = {}\n",
        "size = 7\n",
        "\n",
        "alpha_text[\"John\"] = KeepAlpha(JohnText)\n",
        "chunk_text[\"John\"] = Chunkr(alpha_text[\"John\"],size)\n",
        "\n",
        "alpha_text[\"Matthew\"] = KeepAlpha(MatthewText)\n",
        "chunk_text[\"Matthew\"] = Chunkr(alpha_text[\"Matthew\"], size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1MHg-bnhM08",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "132aaead-6132-43a8-a32b-63d40fd79901"
      },
      "source": [
        "print(\"John Chunks:\", len(chunk_text[\"John\"]))\n",
        "print(\"Matthew Chunks:\", len(chunk_text[\"Matthew\"]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "John Chunks: 149\n",
            "Matthew Chunks: 139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7onw7G0nhPbV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3197f7a5-3d5e-4b49-9d0a-15a4c4ed56bd"
      },
      "source": [
        "joined_chunks = chunk_text[\"John\"] + chunk_text[\"Matthew\"]\n",
        "len(joined_chunks)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEv3gPkUhRlA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f7bdfa6d-e292-4e9c-89eb-5bd79cd45218"
      },
      "source": [
        "# Creates a vector containing the attribute values for each author\n",
        "attvector = []\n",
        "for i in range(len(joined_chunks)):\n",
        "  avector = []\n",
        "  avector = [\n",
        "                  AvgSentLength(str(joined_chunks[i])),\n",
        "                  AvgWordLength(str(joined_chunks[i])),\n",
        "                  AvgSylCount(str(joined_chunks[i])),\n",
        "                  PunctFreq(str(joined_chunks[i])),\n",
        "                  POSTag(str(joined_chunks[i])),\n",
        "                  GFIndex(str(joined_chunks[i])),\n",
        "                  SMOGIndex(str(joined_chunks[i])),\n",
        "                  PronounFreq(str(joined_chunks[i])),\n",
        "                  FunctionFreq(str(joined_chunks[i])),\n",
        "                  NegationFreq(str(joined_chunks[i])),\n",
        "                  LargeWordFreq(str(joined_chunks[i])),\n",
        "                  SmallWordFreq(str(joined_chunks[i])),\n",
        "                  DiffWordCount(str(joined_chunks[i]))\n",
        "  ]\n",
        "  attvector.append(avector)\n",
        "print(attvector[:10])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['long', 'small', 'medium', 'low', 'high', 'college', 'elem', 'medium', 'low', 'low', 'low', 'low', 'high'], ['long', 'small', 'medium', 'medium', 'high', 'college', 'elem', 'high', 'high', 'low', 'low', 'low', 'medium'], ['long', 'small', 'medium', 'medium', 'medium', 'college', 'elem', 'low', 'medium', 'low', 'low', 'low', 'medium'], ['long', 'small', 'medium', 'medium', 'high', 'college', 'elem', 'medium', 'high', 'low', 'low', 'low', 'high'], ['long', 'small', 'medium', 'high', 'high', 'college', 'elem', 'high', 'medium', 'medium', 'low', 'low', 'high'], ['long', 'small', 'medium', 'high', 'low', 'hs', 'elem', 'medium', 'medium', 'low', 'low', 'low', 'low'], ['long', 'small', 'medium', 'medium', 'medium', 'college', 'elem', 'high', 'medium', 'low', 'low', 'low', 'medium'], ['long', 'small', 'medium', 'medium', 'medium', 'college', 'elem', 'low', 'medium', 'low', 'low', 'low', 'medium'], ['long', 'medium', 'medium', 'high', 'low', 'college', 'elem', 'low', 'medium', 'low', 'low', 'low', 'medium'], ['long', 'small', 'medium', 'high', 'low', 'hs', 'elem', 'medium', 'high', 'low', 'low', 'low', 'low']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgrIhKW9hTwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test with a chunk from John\n",
        "test = joined_chunks[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjccCw_5hZWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeledChunks = ([(chunk,\"John\") for chunk in joined_chunks[1:148]] +\n",
        "                 [(chunk,\"Matthew\") for chunk in joined_chunks[148:]])\n",
        "import random\n",
        "random.shuffle(labeledChunks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWESOYuihckz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TextFeatures(text):\n",
        "  return {'sent_length': AvgSentLength(text),\n",
        "          'word_length': AvgWordLength(text),\n",
        "          'syl_count':   AvgSylCount(text),\n",
        "          'punct_freq':  PunctFreq(text),\n",
        "          'pos_rate' :   POSTag(text),\n",
        "          'gf_index':    GFIndex(text),\n",
        "          'smog_index':  SMOGIndex(text),\n",
        "          'pronoun_freq':PronounFreq(text),\n",
        "          'func_freq':   FunctionFreq(text),\n",
        "          'neg_freq':    NegationFreq(text),\n",
        "          'bigwords':    LargeWordFreq(text),\n",
        "          'smallwords':  SmallWordFreq(text),\n",
        "          'wordcount':   DiffWordCount(text)\n",
        "          }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRusoU2shfB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featureSet = [(TextFeatures(chunk),author) for (chunk,author) in labeledChunks]\n",
        "trainSet, testSet = featureSet[30:], featureSet[:30]\n",
        "classifier = nltk.NaiveBayesClassifier.train(trainSet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-bsqfGzhj7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0042089-378c-411b-9dab-abd3895f2c8d"
      },
      "source": [
        "classifier.classify(TextFeatures(KeepAlpha(test)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'John'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQlZLAYDhng9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6be4bcf5-009d-4793-e514-70b447a2e737"
      },
      "source": [
        "print(nltk.classify.accuracy(classifier,testSet))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTctymzGhpkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d601c3e8-c77d-455b-dab6-7c9218440965"
      },
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "              punct_freq = 'medium'         John : Matthe =      3.0 : 1.0\n",
            "                gf_index = 'college'        John : Matthe =      2.9 : 1.0\n",
            "               wordcount = 'medium'         John : Matthe =      2.7 : 1.0\n",
            "            pronoun_freq = 'medium'         John : Matthe =      2.4 : 1.0\n",
            "               syl_count = 'low'          Matthe : John   =      1.9 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}